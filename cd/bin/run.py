#!/usr/bin/python

#import sys
import os
import json
import yaml
from time import sleep
from time import time
from edreporthelper.utilities import run_cmds
from edreporthelper.utilities import get_queue_id
from edreporthelper.utilities import git_clone_repo
from edreporthelper.utilities import execute_http_post
#from shutil import which

def rebuild_deploy(dockerfile="Dockerfile"):

    repo_dir = os.environ["DOCKER_BUILD_DIR"]
    cmds = []
    cmds.append("cd {} && docker-compose stop".format(repo_dir))
    cmds.append("cd {} && docker-compose rm -fv".format(repo_dir))
    cmds.append("cd {} && docker-compose build".format(repo_dir))
    cmds.append("cd {} && docker-compose up -d".format(repo_dir))

    os.environ["TIMEOUT"] = str(os.environ.get("DOCKER_BUILD_TIMEOUT",300))

    try:
        results = run_cmds(cmds)
    except:
        results = {"status":False}
        results["log"] = "TIMED OUT building container"

    return results

class LocalDockerCI(object):

    def __init__(self):
  
        self.deploy_queue_dir = os.environ.get("CD_QUEUE_DIR","/var/tmp/docker/deploy/queue")
        self.token = os.environ["HOST_TOKEN"]
        self.queue_host = os.environ["QUEUE_HOST"]

    def clear_queue(self):

        print "clearing queue {} on init".format(self.deploy_queue_dir)
        return os.system("rm -rf {}/*".format(self.deploy_queue_dir))

    def _get_next_run(self):

        filenames = sorted(os.listdir(self.deploy_queue_dir))
        if not filenames: return

        print 'Queue contains {}'.format(filenames)

        filename = os.path.join(self.deploy_queue_dir,filenames[0])

        print 'Returning {} to run'.format(filename)

        return filename

    def _get_order(self,**kwargs):

        order = {"queue_id":get_queue_id(size=15)}
        order["human_description"] = kwargs["human_description"]
        order["role"] = kwargs["role"]

        order["start_time"] = kwargs["start_time"]
        order["status"] = kwargs["status"]
        order["stop_time"] = str(int(time()))
        order["checkin"] = order["stop_time"]
        order["total_time"] = int(order["stop_time"]) - int(order["start_time"])
        if kwargs.get("log"): order["log"] = kwargs["log"]

        return order

    def _load_webhook(self,orders,file_path):

        inputargs = {"start_time":str(int(time()))}
        inputargs["human_description"] = "loading webhook information"
        inputargs["role"] = "github/webhook_read"
        inputargs["status"] = "in_progress"

        try:
            yaml_str = open(file_path,'r').read()
            loaded_yaml = dict(yaml.load(yaml_str))
            msg = "payload from github webhook loaded and read successfully"
            inputargs["status"] = "completed"
        except:
            loaded_yaml = None
            msg = "ERROR: could not load yaml at {} - skipping ...".format(file_path)
            inputargs["status"] = "failed"

        if not inputargs.get("log"): inputargs["log"] = msg
        print inputargs.get("log")

        os.system("rm -rf {}".format(file_path))
        orders.append(self._get_order(**inputargs))

        return inputargs,loaded_yaml

    def _clone_code(self,orders,loaded_yaml):

        os.environ["REPO_KEY_LOC"] = os.environ.get("REPO_KEY_LOC","/var/lib/jiffy/files/autogenerated/deploy.pem")
        os.environ["DOCKER_BUILD_DIR"] = os.environ.get("DOCKER_BUILD_DIR","/var/tmp/docker/build")
        os.environ["REPO_URL"] = loaded_yaml["repo_url"]
        os.environ["COMMIT_HASH"] = loaded_yaml["commit_hash"]
        os.environ["REPO_BRANCH"] = loaded_yaml.get("branch","master")

        inputargs = {"start_time":str(int(time()))}
        inputargs["human_description"] = "git pull of {} commit {}".format(loaded_yaml["repo_url"],loaded_yaml["commit_hash"])
        inputargs["role"] = "git/clone_code"
        inputargs["status"] = "in_progress"

        results = git_clone_repo()

        if results.get("log"): 
            inputargs["log"] = results["log"]

        if results.get("status") is False: 
            msg = "ERROR: cloning code failed"
            inputargs["status"] = "failed"
        else:
            msg = "cloning code succeeded"
            inputargs["status"] = "completed"

        if not inputargs.get("log"): inputargs["log"] = msg
        print inputargs.get("log")

        orders.append(self._get_order(**inputargs))

        return inputargs

    def _rebuild_deploy(self,orders):

        inputargs = {"start_time":str(int(time()))}
        inputargs["human_description"] = "building of container with {}".format(os.environ["DOCKER_FILE"])
        inputargs["role"] = "docker/build"
        inputargs["status"] = "in_progress"

        results = rebuild_deploy()
        if results.get("log"): inputargs["log"] = results["log"]

        if not results.get("status"):
            inputargs["status"] = "failed"
            msg = "deploying failed"
        else:
            inputargs["status"] = "completed"
            msg = "deploying succeded"

        if not inputargs.get("log"): inputargs["log"] = msg
        print inputargs.get("log")

        orders.append(self._get_order(**inputargs))

        return inputargs

    def _push_container(self,orders):

        inputargs = {"start_time":str(int(time()))}
        inputargs["human_description"] = "pushing of container"
        inputargs["role"] = "docker/push"
        inputargs["status"] = "in_progress"

        results = push_container()
        if results.get("log"): inputargs["log"] = results["log"]

        if not results.get("status"):
            msg = "pushing of container failed"
            inputargs["status"] = "failed"
        else:
            msg = "pushing of container succeeded"
            inputargs["status"] = "completed"

        if not inputargs.get("log"): inputargs["log"] = msg
        print inputargs.get("log")

        orders.append(self._get_order(**inputargs))

        return inputargs

    def _get_new_data(self):

        values = {"status":"running"}
        values["start_time"] = str(int(time()))
        values["automation_phase"] = "continuous_delivery"
        values["orders"] = []
        values["job_name"] = "docker_ci"
        values["run_title"] = "docker_ci"
        values["sched_name"] = "docker_ci"
        values["sched_type"] = "deploy"

        if os.environ.get("PROJECT_ID"): values["project_id"] = os.environ["PROJECT_ID"]
        if os.environ.get("SCHEDULE_ID"): values["schedule_id"] = os.environ["SCHEDULE_ID"]
        if os.environ.get("SCHED_TYPE"): values["sched_type"] = os.environ["SCHED_TYPE"]
        if os.environ.get("SCHED_NAME"): values["sched_name"] = os.environ["SCHED_NAME"]
        if os.environ.get("JOB_NAME"): values["job_name"] = os.environ["JOB_NAME"]
        if os.environ.get("RUN_TITLE"): values["run_title"] = os.environ["RUN_TITLE"]

        values["first_jobs"] = [ values["job_name"] ]
        values["final_jobs"] = [ values["job_name"] ]

        return values

    def _close_pipeline(self,status,data,orders=None):

        data["status"] = status
        data["stop_time"] = str(int(time()))
        data["total_time"] = int(data["stop_time"]) - int(data["start_time"])

        if not orders: return data

        # place other fields orders

        wt = 1
        
        for order in orders:
            if os.environ.get("PROJECT_ID"): order["project_id"] = os.environ["PROJECT_ID"]
            if os.environ.get("SCHEDULE_ID"): order["schedule_id"] = os.environ["SCHEDULE_ID"]
            if os.environ.get("SCHED_TYPE"): order["sched_type"] = os.environ["SCHED_TYPE"]
            if os.environ.get("SCHED_NAME"): order["sched_name"] = os.environ["SCHED_NAME"]
            if os.environ.get("JOB_NAME"): order["job_name"] = os.environ["JOB_NAME"]
            if os.environ.get("JOB_INSTANCE_ID"): order["job_instance_id"] = os.environ["JOB_INSTANCE_ID"]

            order["automation_phase"] = "continuous_delivery"
            order["wt"] = wt
            wt += 1

        data["orders"] = orders

        return data

    def _run(self):

        file_path = self._get_next_run()
        if not file_path: return None,None,None

        # Get new orders
        orders = []

        # load webhook
        wresults,loaded_yaml = self._load_webhook(orders,file_path)
        if wresults.get("status") == "failed": return wresults["status"],orders,loaded_yaml
        
        # clone code
        cresults = self._clone_code(orders,loaded_yaml)
        if cresults.get("status") == "failed": return cresults.get("status"),orders,loaded_yaml

        # deploy code
        dresults = self._rebuild_deploy(orders)
        if dresults.get("status") == "failed": return dresults.get("status"),orders,loaded_yaml

    def run(self):

        while True:

            # Get new data
            data = self._get_new_data()

            status,orders,loaded_yaml = self._run()

            if status is None: 
                #print "Not new yml files to load"
                sleep(1)
                continue

            print "The webhook info has been loaded and processed. \n{}".format(loaded_yaml)

            data["commit"] = loaded_yaml

            publish_vars = loaded_yaml.copy()
            if "status" in publish_vars: del publish_vars["status"]
            data["publish_vars"] = publish_vars

            data = self._close_pipeline(status,data,orders)

            inputargs = {"verify":False}
            inputargs["headers"] = {'content-type': 'application/json'}
            inputargs["headers"]["Token"] = self.token
            inputargs["api_endpoint"] = "https://{}/{}".format(self.queue_host,"api/v1.0/run")
            inputargs["data"] = json.dumps(data)
            execute_http_post(**inputargs)
            sleep(1)

if __name__ == "__main__":
    main = LocalDockerCI()
    main.clear_queue()
    main.run()
